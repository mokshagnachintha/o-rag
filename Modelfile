# Modelfile for local Gemma 3 1B GGUF
# Used by: ollama create gemma3-rag -f Modelfile

FROM ./Gemma-3-1B-it-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q5_K_M.gguf

TEMPLATE """<start_of_turn>user
{{ .Prompt }}<end_of_turn>
<start_of_turn>model
"""

PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER num_predict 512
